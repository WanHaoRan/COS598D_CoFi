Fri May  3 11:18:54 EDT 2024
Your job is running on node(s):
adroit-h11g2
Working directory:
/scratch/network/hw8161/CoFiPruning/tasks/rte_mod2_0.6
nvidia-smi output:
Fri May  3 11:18:54 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:E3:00.0 Off |                    0 |
| N/A   31C    P0              38W / 250W |      2MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
0.91 seconds for warmup
Layer 0, heads  pruned.
Layer 1, heads 10 11 pruned.
Layer 2, heads 11 pruned.
Layer 3, heads 11 pruned.
Layer 4, heads 10 11 pruned.
Layer 5, heads 10 11 pruned.
Layer 6, heads 10 11 pruned.
Layer 7, heads 8 9 10 11 pruned.
Layer 8, heads 10 11 pruned.
Layer 9, heads 9 10 11 pruned.
Layer 10, heads 9 10 11 pruned.
Layer 11, heads 10 11 pruned.
Layer: 0
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([951, 766])
down: torch.Size([766, 951])
Layer: 1
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up: torch.Size([998, 766])
down: torch.Size([766, 998])
Layer: 2
query: torch.Size([704, 766])
key: torch.Size([704, 766])
value: torch.Size([704, 766])
output: torch.Size([766, 704])
up: torch.Size([942, 766])
down: torch.Size([766, 942])
Layer: 3
query: torch.Size([704, 766])
key: torch.Size([704, 766])
value: torch.Size([704, 766])
output: torch.Size([766, 704])
up: torch.Size([856, 766])
down: torch.Size([766, 856])
Layer: 4
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up: torch.Size([953, 766])
down: torch.Size([766, 953])
Layer: 5
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up: torch.Size([939, 766])
down: torch.Size([766, 939])
Layer: 6
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up None
down None
Layer: 7
query: torch.Size([512, 766])
key: torch.Size([512, 766])
value: torch.Size([512, 766])
output: torch.Size([766, 512])
up: torch.Size([676, 766])
down: torch.Size([766, 676])
Layer: 8
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up None
down None
Layer: 9
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up None
down None
Layer: 10
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up None
down None
Layer: 11
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up None
down None
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 0: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 1: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 2: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 3: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 4: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 5: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 6: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 7: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 8: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 9: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 10: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 11: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 12: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 13: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 14: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 15: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 16: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 17: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 18: There are 3 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: sentence1, sentence2, idx.
Round 19: There are 3 batches in the dataset.
Task: rte
Model path: /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod_2/RTE_sparsity0.6/FT-lr3e-5
Model size: 33286777
Sparsity: 0.609
accuracy: 0.6715
seconds/example: 0.001219

