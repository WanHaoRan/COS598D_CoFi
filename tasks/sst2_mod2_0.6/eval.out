Sun Apr 14 01:28:17 EDT 2024
Your job is running on node(s):
adroit-h11g2
Working directory:
/scratch/network/hw8161/CoFiPruning/tasks/sst2_0.6
nvidia-smi output:
Sun Apr 14 01:28:17 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:65:00.0 Off |                    0 |
| N/A   31C    P0              33W / 250W |      2MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads  pruned.
Layer 5, heads  pruned.
Layer 6, heads  pruned.
Layer 7, heads  pruned.
Layer 8, heads  pruned.
Layer 9, heads  pruned.
Layer 10, heads  pruned.
Layer 11, heads  pruned.
layer transformation torch.Size([768, 768])
Layer: 0
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 1
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 2
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 3
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 4
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 5
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 6
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 7
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 8
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 9
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 10
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 11
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Load weights from /scratch/network/hw8161/CoFiPruning/out/SST2/CoFi/SST2_sparsity0.6/best
Model Size before pruning: 85054464
Layer 0, heads 11 pruned.
Layer 1, heads 2 3 7 pruned.
Layer 2, heads 2 4 8 pruned.
Layer 3, heads 1 8 pruned.
Layer 4, heads 8 pruned.
Layer 5, heads 1 4 5 6 pruned.
Layer 6, heads 3 9 10 pruned.
Layer 7, heads 2 3 6 7 11 pruned.
Layer 8, heads 0 3 10 pruned.
Layer 9, heads 0 1 2 3 4 9 pruned.
Layer 10, heads 1 2 3 6 7 8 9 10 pruned.
Layer 11, heads 1 7 11 pruned.
layer transformation torch.Size([768, 766])
Layer: 0
query: torch.Size([704, 766])
key: torch.Size([704, 766])
value: torch.Size([704, 766])
output: torch.Size([766, 704])
up: torch.Size([1007, 766])
down: torch.Size([766, 1007])
Layer: 1
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up: torch.Size([1109, 766])
down: torch.Size([766, 1109])
Layer: 2
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up: torch.Size([1424, 766])
down: torch.Size([766, 1424])
Layer: 3
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up: torch.Size([1079, 766])
down: torch.Size([766, 1079])
Layer: 4
query: torch.Size([704, 766])
key: torch.Size([704, 766])
value: torch.Size([704, 766])
output: torch.Size([766, 704])
up: torch.Size([1050, 766])
down: torch.Size([766, 1050])
Layer: 5
query: torch.Size([512, 766])
key: torch.Size([512, 766])
value: torch.Size([512, 766])
output: torch.Size([766, 512])
up: torch.Size([1055, 766])
down: torch.Size([766, 1055])
Layer: 6
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up: torch.Size([554, 766])
down: torch.Size([766, 554])
Layer: 7
query: torch.Size([448, 766])
key: torch.Size([448, 766])
value: torch.Size([448, 766])
output: torch.Size([766, 448])
up: torch.Size([601, 766])
down: torch.Size([766, 601])
Layer: 8
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up: torch.Size([642, 766])
down: torch.Size([766, 642])
Layer: 9
query: torch.Size([384, 766])
key: torch.Size([384, 766])
value: torch.Size([384, 766])
output: torch.Size([766, 384])
up None
down None
Layer: 10
query: torch.Size([256, 766])
key: torch.Size([256, 766])
value: torch.Size([256, 766])
output: torch.Size([766, 256])
up None
down None
Layer: 11
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up: torch.Size([521, 766])
down: torch.Size([766, 521])
Model Size after pruning: 33936382
Model Size: 33936382
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence.
Round 0: There are 7 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence.
Round 1: There are 7 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence.
Round 2: There are 7 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence.
Round 3: There are 7 batches in the dataset.
The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence.
Round 4: There are 7 batches in the dataset.
Task: sst2
Model path: /scratch/network/hw8161/CoFiPruning/out/SST2/CoFi/SST2_sparsity0.6
Model size: 33936382
Sparsity: 0.601
accuracy: 0.8727
seconds/example: 0.000767

