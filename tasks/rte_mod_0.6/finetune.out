Fri Apr 26 20:15:12 EDT 2024
Your job is running on node(s):
adroit-h11g2
Working directory:
/scratch/network/hw8161/CoFiPruning/tasks/rte_mod_0.6
nvidia-smi output:
Fri Apr 26 20:15:12 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:17:00.0 Off |                    0 |
| N/A   35C    P0              35W / 250W |      2MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
04/26/2024 20:15:16 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
04/26/2024 20:15:16 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=50,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/runs/Apr26_20-15-16_adroit-h11g2,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=100,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=20.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5,
save_on_each_node=False,
save_steps=0,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=57,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
04/26/2024 20:15:16 - INFO - __main__ - Model Arguments:
04/26/2024 20:15:16 - INFO - __main__ - model_name_or_path = bert-base-uncased
04/26/2024 20:15:16 - INFO - __main__ - config_name = None
04/26/2024 20:15:16 - INFO - __main__ - tokenizer_name = None
04/26/2024 20:15:16 - INFO - __main__ - cache_dir = /scratch/network/hw8161/.cache/
04/26/2024 20:15:16 - INFO - __main__ - use_fast_tokenizer = True
04/26/2024 20:15:16 - INFO - __main__ - model_revision = main
04/26/2024 20:15:16 - INFO - __main__ - use_auth_token = False
04/26/2024 20:15:16 - INFO - __main__ - Data Arguments:
04/26/2024 20:15:16 - INFO - __main__ - task_name = rte
04/26/2024 20:15:16 - INFO - __main__ - dataset_name = None
04/26/2024 20:15:16 - INFO - __main__ - t_name = None
04/26/2024 20:15:16 - INFO - __main__ - dataset_config_name = None
04/26/2024 20:15:16 - INFO - __main__ - max_seq_length = 128
04/26/2024 20:15:16 - INFO - __main__ - overwrite_cache = False
04/26/2024 20:15:16 - INFO - __main__ - pad_to_max_length = True
04/26/2024 20:15:16 - INFO - __main__ - max_train_samples = None
04/26/2024 20:15:16 - INFO - __main__ - max_eval_samples = None
04/26/2024 20:15:16 - INFO - __main__ - max_predict_samples = None
04/26/2024 20:15:16 - INFO - __main__ - train_file = None
04/26/2024 20:15:16 - INFO - __main__ - validation_file = None
04/26/2024 20:15:16 - INFO - __main__ - test_file = None
04/26/2024 20:15:16 - INFO - __main__ - Training Arguments:
04/26/2024 20:15:16 - INFO - __main__ - output_dir = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5
04/26/2024 20:15:16 - INFO - __main__ - overwrite_output_dir = True
04/26/2024 20:15:16 - INFO - __main__ - do_train = True
04/26/2024 20:15:16 - INFO - __main__ - do_eval = True
04/26/2024 20:15:16 - INFO - __main__ - do_predict = False
04/26/2024 20:15:16 - INFO - __main__ - evaluation_strategy = IntervalStrategy.STEPS
04/26/2024 20:15:16 - INFO - __main__ - prediction_loss_only = False
04/26/2024 20:15:16 - INFO - __main__ - per_device_train_batch_size = 64
04/26/2024 20:15:16 - INFO - __main__ - per_device_eval_batch_size = 32
04/26/2024 20:15:16 - INFO - __main__ - per_gpu_train_batch_size = None
04/26/2024 20:15:16 - INFO - __main__ - per_gpu_eval_batch_size = None
04/26/2024 20:15:16 - INFO - __main__ - gradient_accumulation_steps = 1
04/26/2024 20:15:16 - INFO - __main__ - eval_accumulation_steps = None
04/26/2024 20:15:16 - INFO - __main__ - learning_rate = 3e-05
04/26/2024 20:15:16 - INFO - __main__ - weight_decay = 0.0
04/26/2024 20:15:16 - INFO - __main__ - adam_beta1 = 0.9
04/26/2024 20:15:16 - INFO - __main__ - adam_beta2 = 0.999
04/26/2024 20:15:16 - INFO - __main__ - adam_epsilon = 1e-08
04/26/2024 20:15:16 - INFO - __main__ - max_grad_norm = 1.0
04/26/2024 20:15:16 - INFO - __main__ - num_train_epochs = 20.0
04/26/2024 20:15:16 - INFO - __main__ - max_steps = -1
04/26/2024 20:15:16 - INFO - __main__ - lr_scheduler_type = SchedulerType.LINEAR
04/26/2024 20:15:16 - INFO - __main__ - warmup_ratio = 0.0
04/26/2024 20:15:16 - INFO - __main__ - warmup_steps = 0
04/26/2024 20:15:16 - INFO - __main__ - log_level = -1
04/26/2024 20:15:16 - INFO - __main__ - log_level_replica = -1
04/26/2024 20:15:16 - INFO - __main__ - log_on_each_node = True
04/26/2024 20:15:16 - INFO - __main__ - logging_dir = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/runs/Apr26_20-15-16_adroit-h11g2
04/26/2024 20:15:16 - INFO - __main__ - logging_strategy = IntervalStrategy.STEPS
04/26/2024 20:15:16 - INFO - __main__ - logging_first_step = False
04/26/2024 20:15:16 - INFO - __main__ - logging_steps = 100
04/26/2024 20:15:16 - INFO - __main__ - logging_nan_inf_filter = True
04/26/2024 20:15:16 - INFO - __main__ - save_strategy = IntervalStrategy.STEPS
04/26/2024 20:15:16 - INFO - __main__ - save_steps = 0
04/26/2024 20:15:16 - INFO - __main__ - save_total_limit = None
04/26/2024 20:15:16 - INFO - __main__ - save_on_each_node = False
04/26/2024 20:15:16 - INFO - __main__ - no_cuda = False
04/26/2024 20:15:16 - INFO - __main__ - seed = 57
04/26/2024 20:15:16 - INFO - __main__ - bf16 = False
04/26/2024 20:15:16 - INFO - __main__ - fp16 = False
04/26/2024 20:15:16 - INFO - __main__ - fp16_opt_level = O1
04/26/2024 20:15:16 - INFO - __main__ - half_precision_backend = auto
04/26/2024 20:15:16 - INFO - __main__ - bf16_full_eval = False
04/26/2024 20:15:16 - INFO - __main__ - fp16_full_eval = False
04/26/2024 20:15:16 - INFO - __main__ - tf32 = None
04/26/2024 20:15:16 - INFO - __main__ - local_rank = -1
04/26/2024 20:15:16 - INFO - __main__ - xpu_backend = None
04/26/2024 20:15:16 - INFO - __main__ - tpu_num_cores = None
04/26/2024 20:15:16 - INFO - __main__ - tpu_metrics_debug = False
04/26/2024 20:15:16 - INFO - __main__ - debug = []
04/26/2024 20:15:16 - INFO - __main__ - dataloader_drop_last = False
04/26/2024 20:15:16 - INFO - __main__ - eval_steps = 50
04/26/2024 20:15:16 - INFO - __main__ - dataloader_num_workers = 0
04/26/2024 20:15:16 - INFO - __main__ - past_index = -1
04/26/2024 20:15:16 - INFO - __main__ - run_name = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5
04/26/2024 20:15:16 - INFO - __main__ - disable_tqdm = False
04/26/2024 20:15:16 - INFO - __main__ - remove_unused_columns = True
04/26/2024 20:15:16 - INFO - __main__ - label_names = None
04/26/2024 20:15:16 - INFO - __main__ - load_best_model_at_end = False
04/26/2024 20:15:16 - INFO - __main__ - metric_for_best_model = None
04/26/2024 20:15:16 - INFO - __main__ - greater_is_better = None
04/26/2024 20:15:16 - INFO - __main__ - ignore_data_skip = False
04/26/2024 20:15:16 - INFO - __main__ - sharded_ddp = []
04/26/2024 20:15:16 - INFO - __main__ - deepspeed = None
04/26/2024 20:15:16 - INFO - __main__ - label_smoothing_factor = 0.0
04/26/2024 20:15:16 - INFO - __main__ - optim = OptimizerNames.ADAMW_HF
04/26/2024 20:15:16 - INFO - __main__ - adafactor = False
04/26/2024 20:15:16 - INFO - __main__ - group_by_length = False
04/26/2024 20:15:16 - INFO - __main__ - length_column_name = length
04/26/2024 20:15:16 - INFO - __main__ - report_to = []
04/26/2024 20:15:16 - INFO - __main__ - ddp_find_unused_parameters = None
04/26/2024 20:15:16 - INFO - __main__ - ddp_bucket_cap_mb = None
04/26/2024 20:15:16 - INFO - __main__ - dataloader_pin_memory = True
04/26/2024 20:15:16 - INFO - __main__ - skip_memory_metrics = True
04/26/2024 20:15:16 - INFO - __main__ - use_legacy_prediction_loop = False
04/26/2024 20:15:16 - INFO - __main__ - push_to_hub = False
04/26/2024 20:15:16 - INFO - __main__ - resume_from_checkpoint = None
04/26/2024 20:15:16 - INFO - __main__ - hub_model_id = None
04/26/2024 20:15:16 - INFO - __main__ - hub_strategy = HubStrategy.EVERY_SAVE
04/26/2024 20:15:16 - INFO - __main__ - hub_token = None
04/26/2024 20:15:16 - INFO - __main__ - gradient_checkpointing = False
04/26/2024 20:15:16 - INFO - __main__ - fp16_backend = auto
04/26/2024 20:15:16 - INFO - __main__ - push_to_hub_model_id = None
04/26/2024 20:15:16 - INFO - __main__ - push_to_hub_organization = None
04/26/2024 20:15:16 - INFO - __main__ - push_to_hub_token = None
04/26/2024 20:15:16 - INFO - __main__ - mp_parameters = 
04/26/2024 20:15:16 - INFO - __main__ - _n_gpu = 1
04/26/2024 20:15:16 - INFO - __main__ - __cached__setup_devices = cuda:0
04/26/2024 20:15:16 - INFO - __main__ - Additional Arguments:
04/26/2024 20:15:16 - INFO - __main__ - test = False
04/26/2024 20:15:16 - INFO - __main__ - ex_name = RTE_sparsity0.6
04/26/2024 20:15:16 - INFO - __main__ - pruning_type = None
04/26/2024 20:15:16 - INFO - __main__ - reg_learning_rate = 0.01
04/26/2024 20:15:16 - INFO - __main__ - scheduler_type = none
04/26/2024 20:15:16 - INFO - __main__ - freeze_embeddings = True
04/26/2024 20:15:16 - INFO - __main__ - pretrained_pruned_model = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6
04/26/2024 20:15:16 - INFO - __main__ - droprate_init = 0.5
04/26/2024 20:15:16 - INFO - __main__ - temperature = 0.6666666666666666
04/26/2024 20:15:16 - INFO - __main__ - prepruning_finetune_epochs = 4
04/26/2024 20:15:16 - INFO - __main__ - lagrangian_warmup_epochs = 20
04/26/2024 20:15:16 - INFO - __main__ - target_sparsity = 0.6
04/26/2024 20:15:16 - INFO - __main__ - sparsity_epsilon = 0
04/26/2024 20:15:16 - INFO - __main__ - distillation_path = textattack/bert-base-uncased-RTE
04/26/2024 20:15:16 - INFO - __main__ - do_distill = True
04/26/2024 20:15:16 - INFO - __main__ - do_layer_distill = True
04/26/2024 20:15:16 - INFO - __main__ - layer_distill_version = 4
04/26/2024 20:15:16 - INFO - __main__ - distill_loss_alpha = 0.9
04/26/2024 20:15:16 - INFO - __main__ - distill_ce_loss_alpha = 0.1
04/26/2024 20:15:16 - INFO - __main__ - distill_temp = 2.0
04/26/2024 20:15:17 - INFO - datasets.builder - Overwrite dataset info from restored data version.
04/26/2024 20:15:17 - INFO - datasets.info - Loading Dataset info from /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353
04/26/2024 20:15:17 - WARNING - datasets.builder - Reusing dataset glue (/scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353)
04/26/2024 20:15:17 - INFO - datasets.info - Loading Dataset info from /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 959.72it/s]
[INFO|configuration_utils.py:648] 2024-04-26 20:15:17,076 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /scratch/network/hw8161/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2024-04-26 20:15:17,076 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "rte",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|configuration_utils.py:648] 2024-04-26 20:15:17,078 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /scratch/network/hw8161/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2024-04-26 20:15:17,078 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|tokenization_utils_base.py:1766] 2024-04-26 20:15:17,081 >> Can't load following files from cache: ['added_tokens_file', 'special_tokens_map_file'] and cannot check if these files are necessary for the tokenizer to operate.
[INFO|tokenization_utils_base.py:1786] 2024-04-26 20:15:17,081 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /scratch/network/hw8161/.cache/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1786] 2024-04-26 20:15:17,081 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /scratch/network/hw8161/.cache/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|tokenization_utils_base.py:1786] 2024-04-26 20:15:17,081 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /scratch/network/hw8161/.cache/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed
[INFO|configuration_utils.py:648] 2024-04-26 20:15:17,083 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /scratch/network/hw8161/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2024-04-26 20:15:17,084 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads  pruned.
Layer 5, heads  pruned.
Layer 6, heads  pruned.
Layer 7, heads  pruned.
Layer 8, heads  pruned.
Layer 9, heads  pruned.
Layer 10, heads  pruned.
Layer 11, heads  pruned.
Layer: 0
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 1
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 2
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 3
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 4
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 5
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 6
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 7
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 8
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 9
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 10
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 11
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads  pruned.
Layer 5, heads  pruned.
Layer 6, heads  pruned.
Layer 7, heads  pruned.
Layer 8, heads  pruned.
Layer 9, heads  pruned.
Layer 10, heads  pruned.
Layer 11, heads  pruned.
layer transformation torch.Size([768, 768])
Layer: 0
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 1
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 2
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 3
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 4
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 5
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 6
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 7
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 8
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 9
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 10
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 11
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
04/26/2024 20:15:25 - INFO - __main__ - CoFiBertForSequenceClassification(
  (bert): CoFiBertModel(
    (embeddings): CoFiBertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): CoFiBertEncoder(
      (layer): ModuleList(
        (0): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
  (layer_transformation): Linear(in_features=768, out_features=768, bias=True)
)
04/26/2024 20:15:25 - INFO - __main__ - Model size: 85054464
[INFO|configuration_utils.py:646] 2024-04-26 20:15:25,905 >> loading configuration file /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/best/config.json
[INFO|configuration_utils.py:684] 2024-04-26 20:15:25,905 >> Model config BertConfig {
  "_name_or_path": "/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/best",
  "architectures": [
    "CoFiBertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "do_layer_distill": true,
  "finetuning_task": "rte",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "entailment",
    "1": "not_entailment"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "entailment": 0,
    "not_entailment": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {
    "0": [],
    "1": [],
    "2": [],
    "3": [],
    "4": [],
    "5": [],
    "6": [],
    "7": [],
    "8": [],
    "9": [],
    "10": [],
    "11": []
  },
  "torch_dtype": "float32",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads  pruned.
Layer 5, heads  pruned.
Layer 6, heads  pruned.
Layer 7, heads  pruned.
Layer 8, heads  pruned.
Layer 9, heads  pruned.
Layer 10, heads  pruned.
Layer 11, heads  pruned.
layer transformation torch.Size([768, 768])
Layer: 0
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 1
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 2
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 3
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 4
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 5
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 6
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 7
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 8
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 9
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 10
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 11
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Load weights from /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/best
Model Size before pruning: 85054464
Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads 7 8 pruned.
Layer 5, heads 1 6 7 11 pruned.
Layer 6, heads 6 10 11 pruned.
Layer 7, heads 7 11 pruned.
Layer 8, heads  pruned.
Layer 9, heads 0 3 4 5 7 9 pruned.
Layer 10, heads 1 4 5 6 9 pruned.
Layer 11, heads 0 1 2 3 4 5 6 7 8 9 10 11 pruned.
layer transformation torch.Size([768, 766])
Layer: 0
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([625, 766])
down: torch.Size([766, 625])
Layer: 1
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([687, 766])
down: torch.Size([766, 687])
Layer: 2
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([680, 766])
down: torch.Size([766, 680])
Layer: 3
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([742, 766])
down: torch.Size([766, 742])
Layer: 4
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up: torch.Size([503, 766])
down: torch.Size([766, 503])
Layer: 5
query: torch.Size([512, 766])
key: torch.Size([512, 766])
value: torch.Size([512, 766])
output: torch.Size([766, 512])
up: torch.Size([585, 766])
down: torch.Size([766, 585])
Layer: 6
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up: torch.Size([581, 766])
down: torch.Size([766, 581])
Layer: 7
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up: torch.Size([655, 766])
down: torch.Size([766, 655])
Layer: 8
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([525, 766])
down: torch.Size([766, 525])
Layer: 9
query: torch.Size([384, 766])
key: torch.Size([384, 766])
value: torch.Size([384, 766])
output: torch.Size([766, 384])
up None
down None
Layer: 10
query: torch.Size([448, 766])
key: torch.Size([448, 766])
value: torch.Size([448, 766])
output: torch.Size([766, 448])
up None
down None
Layer: 11
query: None
key: None
value: None
output: None
up None
down None
Model Size after pruning: 30202511
Model Size: 30202511
Model Size after pruning: 30202511
04/26/2024 20:15:33 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x145ad285b820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
04/26/2024 20:15:33 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353/cache-5e2502420ae59635.arrow
04/26/2024 20:15:33 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x145ad285b820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.
04/26/2024 20:15:33 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353/cache-9af4974096f5b0ee.arrow
04/26/2024 20:15:33 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x145ad285b820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.
04/26/2024 20:15:33 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353/cache-399029b404f18db9.arrow
04/26/2024 20:15:33 - INFO - __main__ - Sample 2105 of the training set: {'sentence1': 'The CBS Evening News commentary segment "Free Speech" , which made its debut with Katie Couric this month, was accused last Friday by Bill Maher of HBO\'s "Real Time with Bill Maher" of being "anything but free speech". Maher said he was asked by CBS News to appear on the segment. But when he asked if he could talk about religion, "that was a dealbreaker from the start". Instead, he said they would send over a list of "acceptable topics". CBS News executive producer Rome Hartman has since responded in an e-mail to TVNewser saying that, "Bill Maher was never told that he couldn\'t discuss religion in a Free Speech segment," and added, "In fact, Free Speech has already addressed religion and we expect others will in the future."', 'sentence2': 'Free Speech is a part of the CBS Evening News.', 'label': 0, 'idx': 2105, 'input_ids': [101, 1996, 6568, 3944, 2739, 8570, 6903, 1000, 2489, 4613, 1000, 1010, 2029, 2081, 2049, 2834, 2007, 9734, 2522, 9496, 2278, 2023, 3204, 1010, 2001, 5496, 2197, 5958, 2011, 3021, 5003, 5886, 1997, 14633, 1005, 1055, 1000, 2613, 2051, 2007, 3021, 5003, 5886, 1000, 1997, 2108, 1000, 2505, 2021, 2489, 4613, 1000, 1012, 5003, 5886, 2056, 2002, 2001, 2356, 2011, 6568, 2739, 2000, 3711, 2006, 1996, 6903, 1012, 2021, 2043, 2002, 2356, 2065, 2002, 2071, 2831, 2055, 4676, 1010, 1000, 2008, 2001, 1037, 3066, 21204, 2013, 1996, 2707, 1000, 1012, 2612, 1010, 2002, 2056, 2027, 2052, 4604, 2058, 1037, 2862, 1997, 1000, 11701, 7832, 1000, 1012, 6568, 2739, 3237, 3135, 4199, 26766, 2038, 2144, 5838, 102, 2489, 4613, 2003, 1037, 2112, 1997, 1996, 6568, 3944, 2739, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
04/26/2024 20:15:33 - INFO - __main__ - Sample 1315 of the training set: {'sentence1': "He said those three detainees are Khalid Sheikh Mohammed - one of the architects of the September 11th attacks on New York and Washington, Abu Zubaydah - who is believed to have been a top al-Qaida strategist, and Abd al-Rahim al-Nashiri - who is believed to have played a key role in the bombing of the USS Cole. All three are being held at the U.S. detention facility at Guantanamo Bay. Hayden said waterboarding was used against the three detainees nearly five years ago because of circumstances at the time, including the belief that additional attacks against the United States were imminent. Hayden defended the CIA's use of extreme interrogation techniques as lawful, and urged lawmakers not to impose restrictions on such methods. Congress is considering legislation that would restrict the CIA to using only the interrogation techniques authorized by the U.S. Army's field manual, which does not include waterboarding.", 'sentence2': 'Abu Zubaydah belongs to al-Qaida.', 'label': 0, 'idx': 1315, 'input_ids': [101, 2002, 2056, 2216, 2093, 26485, 2024, 21828, 12840, 12619, 1011, 2028, 1997, 1996, 8160, 1997, 1996, 2244, 6252, 4491, 2006, 2047, 2259, 1998, 2899, 1010, 8273, 16950, 15907, 18417, 1011, 2040, 2003, 3373, 2000, 2031, 2042, 1037, 2327, 2632, 1011, 1053, 14326, 2050, 2358, 11657, 24063, 1010, 1998, 19935, 2632, 1011, 10958, 14341, 2632, 1011, 10594, 15735, 1011, 2040, 2003, 3373, 2000, 2031, 2209, 1037, 3145, 2535, 1999, 1996, 8647, 1997, 1996, 7234, 5624, 1012, 2035, 2093, 2024, 2108, 2218, 2012, 1996, 1057, 1012, 1055, 1012, 12345, 4322, 2012, 23094, 3016, 1012, 13872, 2056, 2300, 21172, 2001, 2109, 2114, 1996, 2093, 26485, 3053, 2274, 2086, 3283, 2138, 1997, 6214, 2012, 1996, 2051, 1010, 102, 8273, 16950, 15907, 18417, 7460, 2000, 2632, 1011, 1053, 14326, 2050, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
04/26/2024 20:15:33 - INFO - __main__ - Sample 1955 of the training set: {'sentence1': "Please note that Arabic is the language of Quran so it's better to learn it to understand clearly all the miracles in Quran.", 'sentence2': 'Arabic is the language of the Quran.', 'label': 0, 'idx': 1955, 'input_ids': [101, 3531, 3602, 2008, 5640, 2003, 1996, 2653, 1997, 21288, 2061, 2009, 1005, 1055, 2488, 2000, 4553, 2009, 2000, 3305, 4415, 2035, 1996, 17861, 1999, 21288, 1012, 102, 5640, 2003, 1996, 2653, 1997, 1996, 21288, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
04/26/2024 20:15:33 - INFO - datasets.utils.file_utils - HEAD request to https://raw.githubusercontent.com/huggingface/datasets/1.18.0/metrics/glue/glue.py timed out, retrying... [1.0]
04/26/2024 20:15:33 - WARNING - datasets.load - Using the latest cached version of the module from /scratch/network/hw8161/.cache/huggingface/modules/datasets_modules/metrics/glue/1f893b8ccbdd80c366ce0db148773ae919cdbd00f612188de0c14924a82fe984 (last modified on Wed Mar 20 22:26:50 2024) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.
04/26/2024 20:15:33 - INFO - __main__ - ************* 2490 Training Examples Loaded *************
04/26/2024 20:15:33 - INFO - __main__ - ************* 277 Evaluation Examples Loaded *************
[INFO|trainer.py:570] 2024-04-26 20:15:33,939 >> The following columns in the training set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:15:33 - INFO - trainer.trainer_mod - main params, number of params: 31301828, weight_decay: 0.0, lr: 3e-05
04/26/2024 20:15:33 - INFO - trainer.trainer_mod - main params, number of params: 80333, weight_decay: 0.0, lr: 3e-05
04/26/2024 20:15:33 - INFO - trainer.trainer_mod - ***** Running training *****
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Num examples = 2490
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Num Epochs = 20
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Instantaneous batch size per device = 64
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Total train batch size (w. parallel, distributed & accumulation) = 64
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Gradient Accumulation steps = 1
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Total optimization steps = 780
Epoch:   0%|          | 0/20 [00:00<?, ?it/s][INFO|trainer.py:570] 2024-04-26 20:15:33,944 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:15:33 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:15:33 - INFO - trainer.trainer_mod -   Batch size = 32

Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A
Evaluation:  11%|█         | 1/9 [00:00<00:00,  9.43it/s][A
Evaluation:  44%|████▍     | 4/9 [00:00<00:00, 17.65it/s][A
Evaluation:  78%|███████▊  | 7/9 [00:00<00:00, 19.90it/s][AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 19.94it/s]04/26/2024 20:15:34 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:15:34 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6895306859205776, 'eval_loss': 0.92091626, 'step': 0}
04/26/2024 20:15:34 - INFO - trainer.trainer_mod - Saving the best model so far: [Epoch 0 | Step: 0 | Model size: Full | Score: 0.68953]

[INFO|configuration_utils.py:439] 2024-04-26 20:15:34,414 >> Configuration saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/best/config.json
[INFO|modeling_utils.py:1084] 2024-04-26 20:15:34,953 >> Model weights saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/best/pytorch_model.bin

Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A04/26/2024 20:15:35 - INFO - trainer.trainer_mod - v4 Global step: 0, Alignment: tensor([3, 6, 7, 8], device='cuda:0')

Iteration:   3%|▎         | 1/39 [00:00<00:20,  1.83it/s][A
Iteration:   5%|▌         | 2/39 [00:01<00:18,  1.98it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.04it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.06it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.08it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.09it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.09it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.11it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.11it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.11it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.11it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.11it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.11it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.11it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.11it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.11it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.11it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.11it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.11it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.11it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.11it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.11it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.11it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.11it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.11it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.11it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.11it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.11it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.11it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.11it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.11it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.11it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.11it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.11it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.17it/s][A04/26/2024 20:15:53 - INFO - trainer.trainer_mod - Epoch 0 finished. Took 18.53 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:   5%|▌         | 1/20 [00:19<06:11, 19.54s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.11it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.11it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.11it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.11it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.11it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.11it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.11it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.11it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.11it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.11it/s][A[INFO|trainer.py:570] 2024-04-26 20:15:58,704 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:15:58 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:15:58 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:15:58 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.39it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.40it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.52it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.19it/s]04/26/2024 20:15:59 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:15:59 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6462093862815884, 'eval_loss': 0.88717556, 'step': 50}


Iteration:  28%|██▊       | 11/39 [00:05<00:16,  1.68it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:15,  1.79it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:13,  1.87it/s][A
Iteration:  36%|███▌      | 14/39 [00:07<00:12,  1.94it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:12,  1.99it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:11,  2.02it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.04it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.06it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.07it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.08it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.08it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.09it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.09it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.09it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.09it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.09it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.09it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.09it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.09it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.09it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:16:12 - INFO - trainer.trainer_mod - Epoch 1 finished. Took 18.92 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  10%|█         | 2/20 [00:38<05:45, 19.18s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.08it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.09it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.09it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.09it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.09it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.09it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:16:22,905 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:16:22 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:16:22 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:16:22 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.25it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.25it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.36it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.04it/s]04/26/2024 20:16:23 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:16:23 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6714801444043321, 'eval_loss': 0.87773097, 'step': 100}


Iteration:  56%|█████▋    | 22/39 [00:10<00:10,  1.67it/s][A04/26/2024 20:16:23 - INFO - trainer.trainer_mod - v4 Global step: 100, Alignment: tensor([3, 6, 7, 8], device='cuda:0')

Iteration:  59%|█████▉    | 23/39 [00:11<00:08,  1.78it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:08,  1.86it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:07,  1.93it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  1.98it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.01it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.04it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.05it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.06it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.07it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.08it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.09it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.09it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.09it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.09it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.09it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.09it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:16:31 - INFO - trainer.trainer_mod - Epoch 2 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  15%|█▌        | 3/20 [00:57<05:24, 19.08s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.09it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.09it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.09it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:16:47,113 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:16:47 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:16:47 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:16:47 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.25it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.24it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.35it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.04it/s]04/26/2024 20:16:47 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:16:47 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6389891696750902, 'eval_loss': 0.9127586, 'step': 150}


Iteration:  85%|████████▍ | 33/39 [00:16<00:03,  1.68it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  1.78it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:02,  1.87it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  1.93it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:01,  1.98it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.01it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s][A04/26/2024 20:16:50 - INFO - trainer.trainer_mod - Epoch 3 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  20%|██        | 4/20 [01:16<05:04, 19.03s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.09it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.09it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:17:08 - INFO - trainer.trainer_mod - Epoch 4 finished. Took 18.56 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  25%|██▌       | 5/20 [01:34<04:42, 18.86s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:17:11,270 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:17:11 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:17:11 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:17:11 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.23it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.25it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.36it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.04it/s]04/26/2024 20:17:11 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:17:11 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6462093862815884, 'eval_loss': 0.97156566, 'step': 200}


Iteration:  13%|█▎        | 5/39 [00:02<00:21,  1.61it/s][A04/26/2024 20:17:11 - INFO - trainer.trainer_mod - v4 Global step: 200, Alignment: tensor([3, 6, 7, 8], device='cuda:0')

Iteration:  15%|█▌        | 6/39 [00:03<00:18,  1.75it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:17,  1.85it/s][A
Iteration:  21%|██        | 8/39 [00:04<00:16,  1.92it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:15,  1.97it/s][A
Iteration:  26%|██▌       | 10/39 [00:05<00:14,  2.01it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.03it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:13,  2.05it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.07it/s][A
Iteration:  36%|███▌      | 14/39 [00:07<00:12,  2.08it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.08it/s][A
Iteration:  41%|████      | 16/39 [00:08<00:11,  2.09it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.09it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.09it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.09it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.09it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.09it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.09it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.09it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:17:27 - INFO - trainer.trainer_mod - Epoch 5 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  30%|███       | 6/20 [01:53<04:24, 18.89s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:17:35,473 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:17:35 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:17:35 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:17:35 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.24it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.25it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.36it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.04it/s]04/26/2024 20:17:35 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:17:35 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6570397111913358, 'eval_loss': 0.98785204, 'step': 250}


Iteration:  41%|████      | 16/39 [00:08<00:13,  1.67it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:12,  1.78it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:11,  1.87it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:10,  1.93it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  1.98it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.01it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.04it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.05it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.07it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.08it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.08it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.09it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.09it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.09it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.09it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.09it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.09it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.09it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.09it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.09it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:17:46 - INFO - trainer.trainer_mod - Epoch 6 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  35%|███▌      | 7/20 [02:12<04:05, 18.91s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.09it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.09it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:17:59,685 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:17:59 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:17:59 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:17:59 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.26it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.26it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.37it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.05it/s]04/26/2024 20:18:00 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:18:00 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6750902527075813, 'eval_loss': 0.98083824, 'step': 300}


Iteration:  69%|██████▉   | 27/39 [00:13<00:07,  1.67it/s][A04/26/2024 20:18:00 - INFO - trainer.trainer_mod - v4 Global step: 300, Alignment: tensor([3, 6, 7, 8], device='cuda:0')

Iteration:  72%|███████▏  | 28/39 [00:13<00:06,  1.78it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:05,  1.86it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  1.93it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:04,  1.98it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.01it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.04it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.05it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.07it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.08it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.08it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.09it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.15it/s][A04/26/2024 20:18:05 - INFO - trainer.trainer_mod - Epoch 7 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  40%|████      | 8/20 [02:31<03:47, 18.93s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.09it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.09it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.09it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.09it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:18:23,894 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:18:23 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:18:23 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:18:23 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.28it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.27it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.38it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.06it/s]04/26/2024 20:18:24 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:18:24 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6462093862815884, 'eval_loss': 1.0512108, 'step': 350}


Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  1.68it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  1.83it/s][A04/26/2024 20:18:24 - INFO - trainer.trainer_mod - Epoch 8 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  45%|████▌     | 9/20 [02:50<03:28, 18.94s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.09it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.09it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:18:43 - INFO - trainer.trainer_mod - Epoch 9 finished. Took 18.56 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  50%|█████     | 10/20 [03:09<03:08, 18.82s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:18:48,051 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:18:48 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:18:48 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:18:48 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.26it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.25it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.36it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.04it/s]04/26/2024 20:18:48 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:18:48 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6498194945848376, 'eval_loss': 0.9148429, 'step': 400}


Iteration:  26%|██▌       | 10/39 [00:05<00:17,  1.66it/s][A04/26/2024 20:18:48 - INFO - trainer.trainer_mod - v4 Global step: 400, Alignment: tensor([2, 3, 6, 8], device='cuda:0')

Iteration:  28%|██▊       | 11/39 [00:05<00:15,  1.78it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:14,  1.86it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:13,  1.93it/s][A
Iteration:  36%|███▌      | 14/39 [00:07<00:12,  1.98it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.01it/s][A
Iteration:  41%|████      | 16/39 [00:08<00:11,  2.04it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.05it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.07it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.08it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.08it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.09it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.09it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.09it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.09it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.09it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.09it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:19:02 - INFO - trainer.trainer_mod - Epoch 10 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  55%|█████▌    | 11/20 [03:28<02:49, 18.86s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:19:12,257 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:19:12 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:19:12 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:19:12 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.24it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.25it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.09it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.85it/s]04/26/2024 20:19:12 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:19:12 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6389891696750902, 'eval_loss': 0.94392014, 'step': 450}


Iteration:  54%|█████▍    | 21/39 [00:10<00:10,  1.67it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:09,  1.78it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:08,  1.86it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  1.93it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:07,  1.98it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.01it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.04it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.05it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.07it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.08it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.08it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.09it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.09it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.09it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.09it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.09it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.09it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:19:21 - INFO - trainer.trainer_mod - Epoch 11 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  60%|██████    | 12/20 [03:47<02:31, 18.89s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:19:36,464 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:19:36 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:19:36 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:19:36 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.25it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.25it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.35it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.03it/s]04/26/2024 20:19:36 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:19:36 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6642599277978339, 'eval_loss': 0.97052914, 'step': 500}


Iteration:  82%|████████▏ | 32/39 [00:15<00:04,  1.68it/s][A04/26/2024 20:19:37 - INFO - trainer.trainer_mod - v4 Global step: 500, Alignment: tensor([2, 3, 6, 8], device='cuda:0')

Iteration:  85%|████████▍ | 33/39 [00:16<00:03,  1.78it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  1.87it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:02,  1.93it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  1.98it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.01it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.04it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.12it/s][A04/26/2024 20:19:40 - INFO - trainer.trainer_mod - Epoch 12 finished. Took 18.95 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  65%|██████▌   | 13/20 [04:06<02:12, 18.91s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:19:58 - INFO - trainer.trainer_mod - Epoch 13 finished. Took 18.56 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  70%|███████   | 14/20 [04:24<01:52, 18.80s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.09it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:20:00,619 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:20:00 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:20:00 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:20:00 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.23it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.24it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.35it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.03it/s]04/26/2024 20:20:01 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:20:01 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6534296028880866, 'eval_loss': 1.0319395, 'step': 550}


Iteration:  10%|█         | 4/39 [00:02<00:22,  1.58it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:19,  1.73it/s][A
Iteration:  15%|█▌        | 6/39 [00:03<00:17,  1.84it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:16,  1.92it/s][A
Iteration:  21%|██        | 8/39 [00:04<00:15,  1.97it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.01it/s][A
Iteration:  26%|██▌       | 10/39 [00:05<00:14,  2.03it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.05it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:13,  2.07it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.08it/s][A
Iteration:  36%|███▌      | 14/39 [00:07<00:12,  2.08it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.09it/s][A
Iteration:  41%|████      | 16/39 [00:08<00:11,  2.09it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.09it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.09it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.09it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.09it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.09it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.09it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:20:17 - INFO - trainer.trainer_mod - Epoch 14 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  75%|███████▌  | 15/20 [04:43<01:34, 18.85s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:20:24,823 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:20:24 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:20:24 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:20:24 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.25it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.25it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.36it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.04it/s]04/26/2024 20:20:25 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:20:25 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6425992779783394, 'eval_loss': 0.9751413, 'step': 600}


Iteration:  38%|███▊      | 15/39 [00:07<00:14,  1.67it/s][A04/26/2024 20:20:25 - INFO - trainer.trainer_mod - v4 Global step: 600, Alignment: tensor([2, 3, 6, 8], device='cuda:0')

Iteration:  41%|████      | 16/39 [00:08<00:12,  1.78it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:11,  1.86it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  1.93it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:10,  1.98it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.01it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.04it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.05it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.07it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.08it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.08it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.09it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.09it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.09it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.09it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.09it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.09it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.09it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:20:36 - INFO - trainer.trainer_mod - Epoch 15 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  80%|████████  | 16/20 [05:02<01:15, 18.88s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.09it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.09it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.09it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.09it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:20:49,035 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:20:49 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:20:49 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:20:49 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.26it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.26it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.37it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.05it/s]04/26/2024 20:20:49 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:20:49 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6498194945848376, 'eval_loss': 0.9591698, 'step': 650}


Iteration:  67%|██████▋   | 26/39 [00:12<00:07,  1.68it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:06,  1.78it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  1.87it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:05,  1.93it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  1.98it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.01it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.04it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.05it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.07it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.08it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.08it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.09it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.09it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:20:55 - INFO - trainer.trainer_mod - Epoch 16 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  85%|████████▌ | 17/20 [05:21<00:56, 18.91s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.09it/s][A[INFO|trainer.py:570] 2024-04-26 20:21:13,243 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:21:13 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:21:13 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:21:13 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.26it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.23it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.32it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.01it/s]04/26/2024 20:21:13 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:21:13 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6534296028880866, 'eval_loss': 0.9696728, 'step': 700}


Iteration:  95%|█████████▍| 37/39 [00:18<00:01,  1.67it/s][A04/26/2024 20:21:13 - INFO - trainer.trainer_mod - v4 Global step: 700, Alignment: tensor([2, 3, 6, 8], device='cuda:0')

Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  1.78it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  1.91it/s][A04/26/2024 20:21:14 - INFO - trainer.trainer_mod - Epoch 17 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch:  90%|█████████ | 18/20 [05:40<00:37, 18.92s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.10it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.10it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.10it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.10it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.10it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.10it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.10it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.10it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.10it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.10it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.10it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.10it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.10it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.10it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.10it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.10it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:21:33 - INFO - trainer.trainer_mod - Epoch 18 finished. Took 18.56 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  95%|█████████▌| 19/20 [05:59<00:18, 18.81s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:18,  2.10it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.10it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.10it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.10it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.10it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.10it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.10it/s][A[INFO|trainer.py:570] 2024-04-26 20:21:37,401 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence1, sentence2. If idx, sentence1, sentence2 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
04/26/2024 20:21:37 - INFO - trainer.trainer_mod - ***** Running Evaluation *****
04/26/2024 20:21:37 - INFO - trainer.trainer_mod -   Num examples = 277
04/26/2024 20:21:37 - INFO - trainer.trainer_mod -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 22.27it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 22.27it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 23.37it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 23.05it/s]04/26/2024 20:21:37 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
04/26/2024 20:21:37 - INFO - trainer.trainer_mod - Evaluating: {'accuracy': 0.6353790613718412, 'eval_loss': 0.9373591, 'step': 750}


Iteration:  23%|██▎       | 9/39 [00:04<00:18,  1.66it/s][A
Iteration:  26%|██▌       | 10/39 [00:05<00:16,  1.77it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:15,  1.86it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:14,  1.93it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:13,  1.98it/s][A
Iteration:  36%|███▌      | 14/39 [00:07<00:12,  2.01it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.04it/s][A
Iteration:  41%|████      | 16/39 [00:08<00:11,  2.05it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.07it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.08it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.08it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.09it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.09it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.09it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.09it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.09it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.10it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.10it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.10it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.10it/s][A
Iteration:  74%|███████▍  | 29/39 [00:14<00:04,  2.10it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.10it/s][A
Iteration:  79%|███████▉  | 31/39 [00:15<00:03,  2.10it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.10it/s][A
Iteration:  85%|████████▍ | 33/39 [00:16<00:02,  2.10it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.10it/s][A
Iteration:  90%|████████▉ | 35/39 [00:17<00:01,  2.10it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.10it/s][A
Iteration:  95%|█████████▍| 37/39 [00:18<00:00,  2.10it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.10it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A04/26/2024 20:21:52 - INFO - trainer.trainer_mod - Epoch 19 finished. Took 18.96 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.06it/s]
Epoch: 100%|██████████| 20/20 [06:18<00:00, 18.86s/it]Epoch: 100%|██████████| 20/20 [06:18<00:00, 18.91s/it]
[INFO|configuration_utils.py:439] 2024-04-26 20:21:52,067 >> Configuration saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/config.json
[INFO|modeling_utils.py:1084] 2024-04-26 20:21:52,391 >> Model weights saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/pytorch_model.bin
[INFO|tokenization_utils_base.py:2094] 2024-04-26 20:21:52,394 >> tokenizer config file saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2100] 2024-04-26 20:21:52,395 >> Special tokens file saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi_mod/RTE_sparsity0.6/FT-lr3e-5/special_tokens_map.json
04/26/2024 20:21:52 - INFO - __main__ - Training took 395.51 seconds.
