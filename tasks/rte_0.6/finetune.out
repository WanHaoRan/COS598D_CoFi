Sun Mar 24 00:17:59 EDT 2024
Your job is running on node(s):
adroit-h11g2
Working directory:
/scratch/network/hw8161/CoFiPruning/tasks/rte_0.6
nvidia-smi output:
Sun Mar 24 00:17:59 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:CA:00.0 Off |                    0 |
| N/A   31C    P0              34W / 250W |      2MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
03/24/2024 00:18:03 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False
03/24/2024 00:18:03 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
bf16=False,
bf16_full_eval=False,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
debug=[],
deepspeed=None,
disable_tqdm=False,
do_eval=True,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_steps=50,
evaluation_strategy=IntervalStrategy.STEPS,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_model_id=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=3e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=-1,
log_level=-1,
log_level_replica=-1,
log_on_each_node=True,
logging_dir=/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/runs/Mar24_00-18-03_adroit-h11g2,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=100,
logging_strategy=IntervalStrategy.STEPS,
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=20.0,
optim=OptimizerNames.ADAMW_HF,
output_dir=/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=64,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=None,
run_name=/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5,
save_on_each_node=False,
save_steps=0,
save_strategy=IntervalStrategy.STEPS,
save_total_limit=None,
seed=57,
sharded_ddp=[],
skip_memory_metrics=True,
tf32=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_legacy_prediction_loop=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
xpu_backend=None,
)
03/24/2024 00:18:03 - INFO - __main__ - Model Arguments:
03/24/2024 00:18:03 - INFO - __main__ - model_name_or_path = bert-base-uncased
03/24/2024 00:18:03 - INFO - __main__ - config_name = None
03/24/2024 00:18:03 - INFO - __main__ - tokenizer_name = None
03/24/2024 00:18:03 - INFO - __main__ - cache_dir = /scratch/network/hw8161/.cache/
03/24/2024 00:18:03 - INFO - __main__ - use_fast_tokenizer = True
03/24/2024 00:18:03 - INFO - __main__ - model_revision = main
03/24/2024 00:18:03 - INFO - __main__ - use_auth_token = False
03/24/2024 00:18:03 - INFO - __main__ - Data Arguments:
03/24/2024 00:18:03 - INFO - __main__ - task_name = rte
03/24/2024 00:18:03 - INFO - __main__ - dataset_name = None
03/24/2024 00:18:03 - INFO - __main__ - t_name = None
03/24/2024 00:18:03 - INFO - __main__ - dataset_config_name = None
03/24/2024 00:18:03 - INFO - __main__ - max_seq_length = 128
03/24/2024 00:18:03 - INFO - __main__ - overwrite_cache = False
03/24/2024 00:18:03 - INFO - __main__ - pad_to_max_length = True
03/24/2024 00:18:03 - INFO - __main__ - max_train_samples = None
03/24/2024 00:18:03 - INFO - __main__ - max_eval_samples = None
03/24/2024 00:18:03 - INFO - __main__ - max_predict_samples = None
03/24/2024 00:18:03 - INFO - __main__ - train_file = None
03/24/2024 00:18:03 - INFO - __main__ - validation_file = None
03/24/2024 00:18:03 - INFO - __main__ - test_file = None
03/24/2024 00:18:03 - INFO - __main__ - Training Arguments:
03/24/2024 00:18:03 - INFO - __main__ - output_dir = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5
03/24/2024 00:18:03 - INFO - __main__ - overwrite_output_dir = True
03/24/2024 00:18:03 - INFO - __main__ - do_train = True
03/24/2024 00:18:03 - INFO - __main__ - do_eval = True
03/24/2024 00:18:03 - INFO - __main__ - do_predict = False
03/24/2024 00:18:03 - INFO - __main__ - evaluation_strategy = IntervalStrategy.STEPS
03/24/2024 00:18:03 - INFO - __main__ - prediction_loss_only = False
03/24/2024 00:18:03 - INFO - __main__ - per_device_train_batch_size = 64
03/24/2024 00:18:03 - INFO - __main__ - per_device_eval_batch_size = 32
03/24/2024 00:18:03 - INFO - __main__ - per_gpu_train_batch_size = None
03/24/2024 00:18:03 - INFO - __main__ - per_gpu_eval_batch_size = None
03/24/2024 00:18:03 - INFO - __main__ - gradient_accumulation_steps = 1
03/24/2024 00:18:03 - INFO - __main__ - eval_accumulation_steps = None
03/24/2024 00:18:03 - INFO - __main__ - learning_rate = 3e-05
03/24/2024 00:18:03 - INFO - __main__ - weight_decay = 0.0
03/24/2024 00:18:03 - INFO - __main__ - adam_beta1 = 0.9
03/24/2024 00:18:03 - INFO - __main__ - adam_beta2 = 0.999
03/24/2024 00:18:03 - INFO - __main__ - adam_epsilon = 1e-08
03/24/2024 00:18:03 - INFO - __main__ - max_grad_norm = 1.0
03/24/2024 00:18:03 - INFO - __main__ - num_train_epochs = 20.0
03/24/2024 00:18:03 - INFO - __main__ - max_steps = -1
03/24/2024 00:18:03 - INFO - __main__ - lr_scheduler_type = SchedulerType.LINEAR
03/24/2024 00:18:03 - INFO - __main__ - warmup_ratio = 0.0
03/24/2024 00:18:03 - INFO - __main__ - warmup_steps = 0
03/24/2024 00:18:03 - INFO - __main__ - log_level = -1
03/24/2024 00:18:03 - INFO - __main__ - log_level_replica = -1
03/24/2024 00:18:03 - INFO - __main__ - log_on_each_node = True
03/24/2024 00:18:03 - INFO - __main__ - logging_dir = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/runs/Mar24_00-18-03_adroit-h11g2
03/24/2024 00:18:03 - INFO - __main__ - logging_strategy = IntervalStrategy.STEPS
03/24/2024 00:18:03 - INFO - __main__ - logging_first_step = False
03/24/2024 00:18:03 - INFO - __main__ - logging_steps = 100
03/24/2024 00:18:03 - INFO - __main__ - logging_nan_inf_filter = True
03/24/2024 00:18:03 - INFO - __main__ - save_strategy = IntervalStrategy.STEPS
03/24/2024 00:18:03 - INFO - __main__ - save_steps = 0
03/24/2024 00:18:03 - INFO - __main__ - save_total_limit = None
03/24/2024 00:18:03 - INFO - __main__ - save_on_each_node = False
03/24/2024 00:18:03 - INFO - __main__ - no_cuda = False
03/24/2024 00:18:03 - INFO - __main__ - seed = 57
03/24/2024 00:18:03 - INFO - __main__ - bf16 = False
03/24/2024 00:18:03 - INFO - __main__ - fp16 = False
03/24/2024 00:18:03 - INFO - __main__ - fp16_opt_level = O1
03/24/2024 00:18:03 - INFO - __main__ - half_precision_backend = auto
03/24/2024 00:18:03 - INFO - __main__ - bf16_full_eval = False
03/24/2024 00:18:03 - INFO - __main__ - fp16_full_eval = False
03/24/2024 00:18:03 - INFO - __main__ - tf32 = None
03/24/2024 00:18:03 - INFO - __main__ - local_rank = -1
03/24/2024 00:18:03 - INFO - __main__ - xpu_backend = None
03/24/2024 00:18:03 - INFO - __main__ - tpu_num_cores = None
03/24/2024 00:18:03 - INFO - __main__ - tpu_metrics_debug = False
03/24/2024 00:18:03 - INFO - __main__ - debug = []
03/24/2024 00:18:03 - INFO - __main__ - dataloader_drop_last = False
03/24/2024 00:18:03 - INFO - __main__ - eval_steps = 50
03/24/2024 00:18:03 - INFO - __main__ - dataloader_num_workers = 0
03/24/2024 00:18:03 - INFO - __main__ - past_index = -1
03/24/2024 00:18:03 - INFO - __main__ - run_name = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5
03/24/2024 00:18:03 - INFO - __main__ - disable_tqdm = False
03/24/2024 00:18:03 - INFO - __main__ - remove_unused_columns = True
03/24/2024 00:18:03 - INFO - __main__ - label_names = None
03/24/2024 00:18:03 - INFO - __main__ - load_best_model_at_end = False
03/24/2024 00:18:03 - INFO - __main__ - metric_for_best_model = None
03/24/2024 00:18:03 - INFO - __main__ - greater_is_better = None
03/24/2024 00:18:03 - INFO - __main__ - ignore_data_skip = False
03/24/2024 00:18:03 - INFO - __main__ - sharded_ddp = []
03/24/2024 00:18:03 - INFO - __main__ - deepspeed = None
03/24/2024 00:18:03 - INFO - __main__ - label_smoothing_factor = 0.0
03/24/2024 00:18:03 - INFO - __main__ - optim = OptimizerNames.ADAMW_HF
03/24/2024 00:18:03 - INFO - __main__ - adafactor = False
03/24/2024 00:18:03 - INFO - __main__ - group_by_length = False
03/24/2024 00:18:03 - INFO - __main__ - length_column_name = length
03/24/2024 00:18:03 - INFO - __main__ - report_to = []
03/24/2024 00:18:03 - INFO - __main__ - ddp_find_unused_parameters = None
03/24/2024 00:18:03 - INFO - __main__ - ddp_bucket_cap_mb = None
03/24/2024 00:18:03 - INFO - __main__ - dataloader_pin_memory = True
03/24/2024 00:18:03 - INFO - __main__ - skip_memory_metrics = True
03/24/2024 00:18:03 - INFO - __main__ - use_legacy_prediction_loop = False
03/24/2024 00:18:03 - INFO - __main__ - push_to_hub = False
03/24/2024 00:18:03 - INFO - __main__ - resume_from_checkpoint = None
03/24/2024 00:18:03 - INFO - __main__ - hub_model_id = None
03/24/2024 00:18:03 - INFO - __main__ - hub_strategy = HubStrategy.EVERY_SAVE
03/24/2024 00:18:03 - INFO - __main__ - hub_token = None
03/24/2024 00:18:03 - INFO - __main__ - gradient_checkpointing = False
03/24/2024 00:18:03 - INFO - __main__ - fp16_backend = auto
03/24/2024 00:18:03 - INFO - __main__ - push_to_hub_model_id = None
03/24/2024 00:18:03 - INFO - __main__ - push_to_hub_organization = None
03/24/2024 00:18:03 - INFO - __main__ - push_to_hub_token = None
03/24/2024 00:18:03 - INFO - __main__ - mp_parameters = 
03/24/2024 00:18:03 - INFO - __main__ - _n_gpu = 1
03/24/2024 00:18:03 - INFO - __main__ - __cached__setup_devices = cuda:0
03/24/2024 00:18:03 - INFO - __main__ - Additional Arguments:
03/24/2024 00:18:03 - INFO - __main__ - test = False
03/24/2024 00:18:03 - INFO - __main__ - ex_name = RTE_sparsity0.6
03/24/2024 00:18:03 - INFO - __main__ - pruning_type = None
03/24/2024 00:18:03 - INFO - __main__ - reg_learning_rate = 0.01
03/24/2024 00:18:03 - INFO - __main__ - scheduler_type = none
03/24/2024 00:18:03 - INFO - __main__ - freeze_embeddings = True
03/24/2024 00:18:03 - INFO - __main__ - pretrained_pruned_model = /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6
03/24/2024 00:18:03 - INFO - __main__ - droprate_init = 0.5
03/24/2024 00:18:03 - INFO - __main__ - temperature = 0.6666666666666666
03/24/2024 00:18:03 - INFO - __main__ - prepruning_finetune_epochs = 4
03/24/2024 00:18:03 - INFO - __main__ - lagrangian_warmup_epochs = 20
03/24/2024 00:18:03 - INFO - __main__ - target_sparsity = 0.6
03/24/2024 00:18:03 - INFO - __main__ - sparsity_epsilon = 0
03/24/2024 00:18:03 - INFO - __main__ - distillation_path = textattack/bert-base-uncased-RTE
03/24/2024 00:18:03 - INFO - __main__ - do_distill = True
03/24/2024 00:18:03 - INFO - __main__ - do_layer_distill = True
03/24/2024 00:18:03 - INFO - __main__ - layer_distill_version = 4
03/24/2024 00:18:03 - INFO - __main__ - distill_loss_alpha = 0.9
03/24/2024 00:18:03 - INFO - __main__ - distill_ce_loss_alpha = 0.1
03/24/2024 00:18:03 - INFO - __main__ - distill_temp = 2.0
03/24/2024 00:18:03 - INFO - datasets.builder - Overwrite dataset info from restored data version.
03/24/2024 00:18:03 - INFO - datasets.info - Loading Dataset info from /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353
03/24/2024 00:18:03 - WARNING - datasets.builder - Reusing dataset glue (/scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353)
03/24/2024 00:18:03 - INFO - datasets.info - Loading Dataset info from /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 655.91it/s]
[INFO|configuration_utils.py:648] 2024-03-24 00:18:03,591 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /scratch/network/hw8161/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2024-03-24 00:18:03,592 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "finetuning_task": "rte",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|configuration_utils.py:648] 2024-03-24 00:18:03,594 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /scratch/network/hw8161/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2024-03-24 00:18:03,594 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

[INFO|tokenization_utils_base.py:1766] 2024-03-24 00:18:03,598 >> Can't load following files from cache: ['added_tokens_file', 'special_tokens_map_file'] and cannot check if these files are necessary for the tokenizer to operate.
[INFO|tokenization_utils_base.py:1786] 2024-03-24 00:18:03,598 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /scratch/network/hw8161/.cache/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99
[INFO|tokenization_utils_base.py:1786] 2024-03-24 00:18:03,598 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /scratch/network/hw8161/.cache/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4
[INFO|tokenization_utils_base.py:1786] 2024-03-24 00:18:03,598 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /scratch/network/hw8161/.cache/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed
[INFO|configuration_utils.py:648] 2024-03-24 00:18:03,601 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /scratch/network/hw8161/.cache/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e
[INFO|configuration_utils.py:684] 2024-03-24 00:18:03,602 >> Model config BertConfig {
  "_name_or_path": "bert-base-uncased",
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads  pruned.
Layer 5, heads  pruned.
Layer 6, heads  pruned.
Layer 7, heads  pruned.
Layer 8, heads  pruned.
Layer 9, heads  pruned.
Layer 10, heads  pruned.
Layer 11, heads  pruned.
Layer: 0
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 1
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 2
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 3
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 4
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 5
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 6
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 7
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 8
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 9
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 10
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 11
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads  pruned.
Layer 5, heads  pruned.
Layer 6, heads  pruned.
Layer 7, heads  pruned.
Layer 8, heads  pruned.
Layer 9, heads  pruned.
Layer 10, heads  pruned.
Layer 11, heads  pruned.
layer transformation torch.Size([768, 768])
Layer: 0
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 1
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 2
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 3
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 4
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 5
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 6
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 7
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 8
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 9
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 10
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 11
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
03/24/2024 00:18:12 - INFO - __main__ - CoFiBertForSequenceClassification(
  (bert): CoFiBertModel(
    (embeddings): CoFiBertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): CoFiBertEncoder(
      (layer): ModuleList(
        (0): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (1): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (2): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (3): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (4): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (5): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (6): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (7): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (8): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (9): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (10): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
        (11): CoFiBertLayer(
          (attention): CoFiBertAttention(
            (self): CoFiBertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): CoFiBertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): CoFiBertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): CoFiLayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=2, bias=True)
  (layer_transformation): Linear(in_features=768, out_features=768, bias=True)
)
03/24/2024 00:18:12 - INFO - __main__ - Model size: 85054464
[INFO|configuration_utils.py:646] 2024-03-24 00:18:12,419 >> loading configuration file /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/best/config.json
[INFO|configuration_utils.py:684] 2024-03-24 00:18:12,419 >> Model config BertConfig {
  "_name_or_path": "/scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/best",
  "architectures": [
    "CoFiBertForSequenceClassification"
  ],
  "attention_probs_dropout_prob": 0.1,
  "classifier_dropout": null,
  "do_layer_distill": true,
  "finetuning_task": "rte",
  "gradient_checkpointing": false,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "entailment",
    "1": "not_entailment"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "label2id": {
    "entailment": 0,
    "not_entailment": 1
  },
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "output_attentions": true,
  "output_hidden_states": true,
  "pad_token_id": 0,
  "position_embedding_type": "absolute",
  "pruned_heads": {
    "0": [],
    "1": [],
    "2": [],
    "3": [],
    "4": [],
    "5": [],
    "6": [],
    "7": [],
    "8": [],
    "9": [],
    "10": [],
    "11": []
  },
  "torch_dtype": "float32",
  "transformers_version": "4.17.0",
  "type_vocab_size": 2,
  "use_cache": true,
  "vocab_size": 30522
}

Layer 0, heads  pruned.
Layer 1, heads  pruned.
Layer 2, heads  pruned.
Layer 3, heads  pruned.
Layer 4, heads  pruned.
Layer 5, heads  pruned.
Layer 6, heads  pruned.
Layer 7, heads  pruned.
Layer 8, heads  pruned.
Layer 9, heads  pruned.
Layer 10, heads  pruned.
Layer 11, heads  pruned.
layer transformation torch.Size([768, 768])
Layer: 0
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 1
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 2
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 3
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 4
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 5
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 6
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 7
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 8
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 9
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 10
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Layer: 11
query: torch.Size([768, 768])
key: torch.Size([768, 768])
value: torch.Size([768, 768])
output: torch.Size([768, 768])
up: torch.Size([3072, 768])
down: torch.Size([768, 3072])
Load weights from /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/best
Model Size before pruning: 85054464
Layer 0, heads  pruned.
Layer 1, heads 3 pruned.
Layer 2, heads 3 4 8 pruned.
Layer 3, heads 2 4 pruned.
Layer 4, heads 8 pruned.
Layer 5, heads 5 pruned.
Layer 6, heads 1 2 4 7 9 10 11 pruned.
Layer 7, heads 2 6 7 11 pruned.
Layer 8, heads  pruned.
Layer 9, heads 3 4 5 7 9 pruned.
Layer 10, heads 1 4 5 6 9 11 pruned.
Layer 11, heads 0 3 5 6 7 8 10 11 pruned.
layer transformation torch.Size([768, 766])
Layer: 0
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([1014, 766])
down: torch.Size([766, 1014])
Layer: 1
query: torch.Size([704, 766])
key: torch.Size([704, 766])
value: torch.Size([704, 766])
output: torch.Size([766, 704])
up: torch.Size([1114, 766])
down: torch.Size([766, 1114])
Layer: 2
query: torch.Size([576, 766])
key: torch.Size([576, 766])
value: torch.Size([576, 766])
output: torch.Size([766, 576])
up: torch.Size([1126, 766])
down: torch.Size([766, 1126])
Layer: 3
query: torch.Size([640, 766])
key: torch.Size([640, 766])
value: torch.Size([640, 766])
output: torch.Size([766, 640])
up: torch.Size([820, 766])
down: torch.Size([766, 820])
Layer: 4
query: torch.Size([704, 766])
key: torch.Size([704, 766])
value: torch.Size([704, 766])
output: torch.Size([766, 704])
up: torch.Size([1042, 766])
down: torch.Size([766, 1042])
Layer: 5
query: torch.Size([704, 766])
key: torch.Size([704, 766])
value: torch.Size([704, 766])
output: torch.Size([766, 704])
up: torch.Size([1173, 766])
down: torch.Size([766, 1173])
Layer: 6
query: torch.Size([320, 766])
key: torch.Size([320, 766])
value: torch.Size([320, 766])
output: torch.Size([766, 320])
up: torch.Size([538, 766])
down: torch.Size([766, 538])
Layer: 7
query: torch.Size([512, 766])
key: torch.Size([512, 766])
value: torch.Size([512, 766])
output: torch.Size([766, 512])
up: torch.Size([664, 766])
down: torch.Size([766, 664])
Layer: 8
query: torch.Size([768, 766])
key: torch.Size([768, 766])
value: torch.Size([768, 766])
output: torch.Size([766, 768])
up: torch.Size([710, 766])
down: torch.Size([766, 710])
Layer: 9
query: torch.Size([448, 766])
key: torch.Size([448, 766])
value: torch.Size([448, 766])
output: torch.Size([766, 448])
up None
down None
Layer: 10
query: torch.Size([384, 766])
key: torch.Size([384, 766])
value: torch.Size([384, 766])
output: torch.Size([766, 384])
up: torch.Size([197, 766])
down: torch.Size([766, 197])
Layer: 11
query: torch.Size([256, 766])
key: torch.Size([256, 766])
value: torch.Size([256, 766])
output: torch.Size([766, 256])
up None
down None
Model Size after pruning: 33734282
Model Size: 33734282
Model Size after pruning: 33734282
03/24/2024 00:18:17 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x1545e99bd700> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
03/24/2024 00:18:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353/cache-5e2502420ae59635.arrow
03/24/2024 00:18:17 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x1545e7203a60> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.
03/24/2024 00:18:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353/cache-9af4974096f5b0ee.arrow
03/24/2024 00:18:17 - INFO - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x1545e9a26940> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead.
03/24/2024 00:18:17 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /scratch/network/hw8161/.cache/glue/rte/1.0.0/a420f5e518f42454003587c47467370329f9fc0c6508d1ae0c45b58ea266a353/cache-399029b404f18db9.arrow
03/24/2024 00:18:17 - INFO - __main__ - Sample 2105 of the training set: {'sentence1': 'The CBS Evening News commentary segment "Free Speech" , which made its debut with Katie Couric this month, was accused last Friday by Bill Maher of HBO\'s "Real Time with Bill Maher" of being "anything but free speech". Maher said he was asked by CBS News to appear on the segment. But when he asked if he could talk about religion, "that was a dealbreaker from the start". Instead, he said they would send over a list of "acceptable topics". CBS News executive producer Rome Hartman has since responded in an e-mail to TVNewser saying that, "Bill Maher was never told that he couldn\'t discuss religion in a Free Speech segment," and added, "In fact, Free Speech has already addressed religion and we expect others will in the future."', 'sentence2': 'Free Speech is a part of the CBS Evening News.', 'label': 0, 'idx': 2105, 'input_ids': [101, 1996, 6568, 3944, 2739, 8570, 6903, 1000, 2489, 4613, 1000, 1010, 2029, 2081, 2049, 2834, 2007, 9734, 2522, 9496, 2278, 2023, 3204, 1010, 2001, 5496, 2197, 5958, 2011, 3021, 5003, 5886, 1997, 14633, 1005, 1055, 1000, 2613, 2051, 2007, 3021, 5003, 5886, 1000, 1997, 2108, 1000, 2505, 2021, 2489, 4613, 1000, 1012, 5003, 5886, 2056, 2002, 2001, 2356, 2011, 6568, 2739, 2000, 3711, 2006, 1996, 6903, 1012, 2021, 2043, 2002, 2356, 2065, 2002, 2071, 2831, 2055, 4676, 1010, 1000, 2008, 2001, 1037, 3066, 21204, 2013, 1996, 2707, 1000, 1012, 2612, 1010, 2002, 2056, 2027, 2052, 4604, 2058, 1037, 2862, 1997, 1000, 11701, 7832, 1000, 1012, 6568, 2739, 3237, 3135, 4199, 26766, 2038, 2144, 5838, 102, 2489, 4613, 2003, 1037, 2112, 1997, 1996, 6568, 3944, 2739, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
03/24/2024 00:18:17 - INFO - __main__ - Sample 1315 of the training set: {'sentence1': "He said those three detainees are Khalid Sheikh Mohammed - one of the architects of the September 11th attacks on New York and Washington, Abu Zubaydah - who is believed to have been a top al-Qaida strategist, and Abd al-Rahim al-Nashiri - who is believed to have played a key role in the bombing of the USS Cole. All three are being held at the U.S. detention facility at Guantanamo Bay. Hayden said waterboarding was used against the three detainees nearly five years ago because of circumstances at the time, including the belief that additional attacks against the United States were imminent. Hayden defended the CIA's use of extreme interrogation techniques as lawful, and urged lawmakers not to impose restrictions on such methods. Congress is considering legislation that would restrict the CIA to using only the interrogation techniques authorized by the U.S. Army's field manual, which does not include waterboarding.", 'sentence2': 'Abu Zubaydah belongs to al-Qaida.', 'label': 0, 'idx': 1315, 'input_ids': [101, 2002, 2056, 2216, 2093, 26485, 2024, 21828, 12840, 12619, 1011, 2028, 1997, 1996, 8160, 1997, 1996, 2244, 6252, 4491, 2006, 2047, 2259, 1998, 2899, 1010, 8273, 16950, 15907, 18417, 1011, 2040, 2003, 3373, 2000, 2031, 2042, 1037, 2327, 2632, 1011, 1053, 14326, 2050, 2358, 11657, 24063, 1010, 1998, 19935, 2632, 1011, 10958, 14341, 2632, 1011, 10594, 15735, 1011, 2040, 2003, 3373, 2000, 2031, 2209, 1037, 3145, 2535, 1999, 1996, 8647, 1997, 1996, 7234, 5624, 1012, 2035, 2093, 2024, 2108, 2218, 2012, 1996, 1057, 1012, 1055, 1012, 12345, 4322, 2012, 23094, 3016, 1012, 13872, 2056, 2300, 21172, 2001, 2109, 2114, 1996, 2093, 26485, 3053, 2274, 2086, 3283, 2138, 1997, 6214, 2012, 1996, 2051, 1010, 102, 8273, 16950, 15907, 18417, 7460, 2000, 2632, 1011, 1053, 14326, 2050, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}.
03/24/2024 00:18:17 - INFO - __main__ - Sample 1955 of the training set: {'sentence1': "Please note that Arabic is the language of Quran so it's better to learn it to understand clearly all the miracles in Quran.", 'sentence2': 'Arabic is the language of the Quran.', 'label': 0, 'idx': 1955, 'input_ids': [101, 3531, 3602, 2008, 5640, 2003, 1996, 2653, 1997, 21288, 2061, 2009, 1005, 1055, 2488, 2000, 4553, 2009, 2000, 3305, 4415, 2035, 1996, 17861, 1999, 21288, 1012, 102, 5640, 2003, 1996, 2653, 1997, 1996, 21288, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
03/24/2024 00:18:17 - INFO - datasets.utils.file_utils - HEAD request to https://raw.githubusercontent.com/huggingface/datasets/1.18.0/metrics/glue/glue.py timed out, retrying... [1.0]
03/24/2024 00:18:18 - WARNING - datasets.load - Using the latest cached version of the module from /scratch/network/hw8161/.cache/huggingface/modules/datasets_modules/metrics/glue/1f893b8ccbdd80c366ce0db148773ae919cdbd00f612188de0c14924a82fe984 (last modified on Wed Mar 20 22:26:50 2024) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.
03/24/2024 00:18:18 - INFO - __main__ - ************* 2490 Training Examples Loaded *************
03/24/2024 00:18:18 - INFO - __main__ - ************* 277 Evaluation Examples Loaded *************
[INFO|trainer.py:570] 2024-03-24 00:18:18,250 >> The following columns in the training set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:18:18 - INFO - trainer.trainer - main params, number of params: 34830024, weight_decay: 0.0, lr: 3e-05
03/24/2024 00:18:18 - INFO - trainer.trainer - main params, number of params: 83908, weight_decay: 0.0, lr: 3e-05
03/24/2024 00:18:18 - INFO - trainer.trainer - ***** Running training *****
03/24/2024 00:18:18 - INFO - trainer.trainer -   Num examples = 2490
03/24/2024 00:18:18 - INFO - trainer.trainer -   Num Epochs = 20
03/24/2024 00:18:18 - INFO - trainer.trainer -   Instantaneous batch size per device = 64
03/24/2024 00:18:18 - INFO - trainer.trainer -   Total train batch size (w. parallel, distributed & accumulation) = 64
03/24/2024 00:18:18 - INFO - trainer.trainer -   Gradient Accumulation steps = 1
03/24/2024 00:18:18 - INFO - trainer.trainer -   Total optimization steps = 780
Epoch:   0%|          | 0/20 [00:00<?, ?it/s][INFO|trainer.py:570] 2024-03-24 00:18:18,255 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:18:18 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:18:18 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:18:18 - INFO - trainer.trainer -   Batch size = 32

Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A
Evaluation:  11%|█         | 1/9 [00:00<00:00,  9.30it/s][A
Evaluation:  44%|████▍     | 4/9 [00:00<00:00, 17.07it/s][A
Evaluation:  78%|███████▊  | 7/9 [00:00<00:00, 19.13it/s][AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 19.20it/s]03/24/2024 00:18:18 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:18:18 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.703971119133574, 'eval_loss': 0.84367317, 'step': 0}
03/24/2024 00:18:18 - INFO - trainer.trainer - Saving the best model so far: [Epoch 0 | Step: 0 | Model size: Full | Score: 0.70397]

[INFO|configuration_utils.py:439] 2024-03-24 00:18:18,741 >> Configuration saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/best/config.json
[INFO|modeling_utils.py:1084] 2024-03-24 00:18:19,159 >> Model weights saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/best/pytorch_model.bin

Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A03/24/2024 00:18:19 - INFO - trainer.trainer - v4 Global step: 0, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:   3%|▎         | 1/39 [00:00<00:21,  1.79it/s][A
Iteration:   5%|▌         | 2/39 [00:01<00:18,  1.98it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:17,  2.05it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.08it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:16,  2.10it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.11it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:15,  2.12it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.13it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.13it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.13it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.13it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.13it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.13it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.13it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.13it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.13it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.13it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.13it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:15<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:16<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:17<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:18:37 - INFO - trainer.trainer - Epoch 0 finished. Took 18.29 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.13it/s]
Epoch:   5%|▌         | 1/20 [00:19<06:04, 19.19s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:18:42,591 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:18:42 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:18:42 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:18:42 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.43it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.43it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.49it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.19it/s]03/24/2024 00:18:43 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:18:43 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6895306859205776, 'eval_loss': 0.7679524, 'step': 50}


Iteration:  28%|██▊       | 11/39 [00:05<00:16,  1.68it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:15,  1.80it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:13,  1.89it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:12,  1.96it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.01it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:11,  2.05it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.08it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  2.09it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.11it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.12it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.12it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.13it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.13it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.13it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:18:56 - INFO - trainer.trainer - Epoch 1 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  10%|█         | 2/20 [00:37<05:39, 18.84s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:19:06,328 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:19:06 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:19:06 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:19:06 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.44it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.44it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.51it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.20it/s]03/24/2024 00:19:06 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:19:06 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6823104693140795, 'eval_loss': 0.7807182, 'step': 100}


Iteration:  56%|█████▋    | 22/39 [00:10<00:10,  1.69it/s][A03/24/2024 00:19:07 - INFO - trainer.trainer - v4 Global step: 100, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:  59%|█████▉    | 23/39 [00:11<00:08,  1.80it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  1.89it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:07,  1.96it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.01it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.05it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.07it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.09it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.11it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.12it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.12it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.13it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.13it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.13it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.20it/s][A03/24/2024 00:19:14 - INFO - trainer.trainer - Epoch 2 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  15%|█▌        | 3/20 [00:56<05:18, 18.73s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:14<00:03,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:19:30,070 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:19:30 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:19:30 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:19:30 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.42it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.39it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.44it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.14it/s]03/24/2024 00:19:30 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:19:30 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6859205776173285, 'eval_loss': 0.7922012, 'step': 150}


Iteration:  85%|████████▍ | 33/39 [00:15<00:03,  1.69it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  1.80it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:02,  1.89it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  1.96it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.01it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.05it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.14it/s][A03/24/2024 00:19:33 - INFO - trainer.trainer - Epoch 3 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  20%|██        | 4/20 [01:14<04:58, 18.68s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:14<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:15<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:16<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:17<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:19:51 - INFO - trainer.trainer - Epoch 4 finished. Took 18.18 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.15it/s]
Epoch:  25%|██▌       | 5/20 [01:33<04:37, 18.50s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:19:53,762 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:19:53 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:19:53 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:19:53 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.42it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.43it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.50it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.19it/s]03/24/2024 00:19:54 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:19:54 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6714801444043321, 'eval_loss': 0.82490575, 'step': 200}


Iteration:  13%|█▎        | 5/39 [00:02<00:20,  1.62it/s][A03/24/2024 00:19:54 - INFO - trainer.trainer - v4 Global step: 200, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:  15%|█▌        | 6/39 [00:03<00:18,  1.77it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:17,  1.87it/s][A
Iteration:  21%|██        | 8/39 [00:04<00:15,  1.95it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.01it/s][A
Iteration:  26%|██▌       | 10/39 [00:05<00:14,  2.04it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.07it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:12,  2.09it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.11it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.12it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.12it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.12it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.13it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.13it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.13it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:20:10 - INFO - trainer.trainer - Epoch 5 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  30%|███       | 6/20 [01:51<04:19, 18.53s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:20:17,500 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:20:17 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:20:17 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:20:17 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.43it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.44it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.51it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.20it/s]03/24/2024 00:20:17 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:20:17 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6895306859205776, 'eval_loss': 0.80858403, 'step': 250}


Iteration:  41%|████      | 16/39 [00:07<00:13,  1.69it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:12,  1.80it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:11,  1.89it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:10,  1.96it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.01it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.05it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.07it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.09it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.11it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.12it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.12it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.13it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.13it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.13it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.13it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.20it/s][A03/24/2024 00:20:28 - INFO - trainer.trainer - Epoch 6 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  35%|███▌      | 7/20 [02:10<04:01, 18.55s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:20:41,238 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:20:41 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:20:41 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:20:41 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.44it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.44it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.51it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.20it/s]03/24/2024 00:20:41 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:20:41 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6787003610108303, 'eval_loss': 0.8266933, 'step': 300}


Iteration:  69%|██████▉   | 27/39 [00:13<00:07,  1.69it/s][A03/24/2024 00:20:41 - INFO - trainer.trainer - v4 Global step: 300, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:  72%|███████▏  | 28/39 [00:13<00:06,  1.80it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:05,  1.89it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  1.96it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.01it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.05it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.08it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.09it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.11it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.12it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.12it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.13it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.20it/s][A03/24/2024 00:20:47 - INFO - trainer.trainer - Epoch 7 finished. Took 18.59 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  40%|████      | 8/20 [02:28<03:42, 18.57s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.13it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.13it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:14<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:15<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:16<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:21:04,980 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:21:04 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:21:04 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:21:04 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.42it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.43it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.50it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.19it/s]03/24/2024 00:21:05 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:21:05 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6859205776173285, 'eval_loss': 0.8284298, 'step': 350}


Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  1.69it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  1.85it/s][A03/24/2024 00:21:05 - INFO - trainer.trainer - Epoch 8 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  45%|████▌     | 9/20 [02:47<03:24, 18.58s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:14<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:15<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:16<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:17<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:21:23 - INFO - trainer.trainer - Epoch 9 finished. Took 18.18 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.15it/s]
Epoch:  50%|█████     | 10/20 [03:05<03:04, 18.45s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:21:28,666 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:21:28 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:21:28 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:21:28 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.44it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.44it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.16it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 21.95it/s]03/24/2024 00:21:29 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:21:29 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6823104693140795, 'eval_loss': 0.816187, 'step': 400}


Iteration:  26%|██▌       | 10/39 [00:05<00:17,  1.68it/s][A03/24/2024 00:21:29 - INFO - trainer.trainer - v4 Global step: 400, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:  28%|██▊       | 11/39 [00:05<00:15,  1.79it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:14,  1.89it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:13,  1.96it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:12,  2.01it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.04it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:11,  2.07it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.09it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.11it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.12it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.12it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.13it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.13it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.13it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:21:42 - INFO - trainer.trainer - Epoch 10 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  55%|█████▌    | 11/20 [03:24<02:46, 18.50s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:21:52,409 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:21:52 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:21:52 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:21:52 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.42it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.42it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.49it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.18it/s]03/24/2024 00:21:52 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:21:52 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6750902527075813, 'eval_loss': 0.86070156, 'step': 450}


Iteration:  54%|█████▍    | 21/39 [00:10<00:10,  1.69it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:09,  1.80it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:08,  1.89it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  1.96it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.01it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.05it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.07it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.09it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.11it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.12it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.12it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.13it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.13it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.13it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.20it/s][A03/24/2024 00:22:01 - INFO - trainer.trainer - Epoch 11 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  60%|██████    | 12/20 [03:42<02:28, 18.53s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:22:16,146 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:22:16 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:22:16 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:22:16 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.44it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.44it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.51it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.20it/s]03/24/2024 00:22:16 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:22:16 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6678700361010831, 'eval_loss': 0.8310025, 'step': 500}


Iteration:  82%|████████▏ | 32/39 [00:15<00:04,  1.69it/s][A03/24/2024 00:22:16 - INFO - trainer.trainer - v4 Global step: 500, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:  85%|████████▍ | 33/39 [00:15<00:03,  1.80it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  1.89it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:02,  1.96it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.01it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.05it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.07it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.16it/s][A03/24/2024 00:22:19 - INFO - trainer.trainer - Epoch 12 finished. Took 18.59 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  65%|██████▌   | 13/20 [04:01<02:09, 18.55s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:14<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:15<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:16<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:17<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:22:37 - INFO - trainer.trainer - Epoch 13 finished. Took 18.18 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.15it/s]
Epoch:  70%|███████   | 14/20 [04:19<01:50, 18.44s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:22:39,836 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:22:39 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:22:39 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:22:39 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.43it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.44it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.50it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.19it/s]03/24/2024 00:22:40 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:22:40 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6787003610108303, 'eval_loss': 0.8330119, 'step': 550}


Iteration:  10%|█         | 4/39 [00:02<00:22,  1.58it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:19,  1.75it/s][A
Iteration:  15%|█▌        | 6/39 [00:03<00:17,  1.86it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:16,  1.95it/s][A
Iteration:  21%|██        | 8/39 [00:04<00:15,  2.00it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.04it/s][A
Iteration:  26%|██▌       | 10/39 [00:05<00:13,  2.07it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.09it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:12,  2.11it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.12it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.12it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.13it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.13it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.13it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:22:56 - INFO - trainer.trainer - Epoch 14 finished. Took 18.59 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  75%|███████▌  | 15/20 [04:38<01:32, 18.48s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:23:03,573 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:23:03 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:23:03 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:23:03 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.44it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.43it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.51it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.20it/s]03/24/2024 00:23:03 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:23:03 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6714801444043321, 'eval_loss': 0.8247572, 'step': 600}


Iteration:  38%|███▊      | 15/39 [00:07<00:14,  1.69it/s][A03/24/2024 00:23:04 - INFO - trainer.trainer - v4 Global step: 600, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:  41%|████      | 16/39 [00:07<00:12,  1.80it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:11,  1.89it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:10,  1.96it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.01it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:09,  2.05it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.07it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:08,  2.09it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.11it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.12it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.12it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.13it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.13it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.13it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:23:15 - INFO - trainer.trainer - Epoch 15 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  80%|████████  | 16/20 [04:56<01:14, 18.52s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:23:27,310 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:23:27 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:23:27 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:23:27 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.42it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.43it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.49it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.19it/s]03/24/2024 00:23:27 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:23:27 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6823104693140795, 'eval_loss': 0.8381257, 'step': 650}


Iteration:  67%|██████▋   | 26/39 [00:12<00:07,  1.69it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:06,  1.80it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  1.89it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:05,  1.96it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.01it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.05it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.07it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.09it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.11it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.12it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.12it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.13it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.13it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.20it/s][A03/24/2024 00:23:33 - INFO - trainer.trainer - Epoch 16 finished. Took 18.59 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  85%|████████▌ | 17/20 [05:15<00:55, 18.54s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.14it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.14it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.14it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.14it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:14<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:15<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:16<00:01,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:23:51,046 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:23:51 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:23:51 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:23:51 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.44it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.44it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.51it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.20it/s]03/24/2024 00:23:51 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:23:51 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6823104693140795, 'eval_loss': 0.8583702, 'step': 700}


Iteration:  95%|█████████▍| 37/39 [00:17<00:01,  1.69it/s][A03/24/2024 00:23:51 - INFO - trainer.trainer - v4 Global step: 700, Alignment: tensor([ 2,  5,  8, 10], device='cuda:0')

Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  1.80it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  1.94it/s][A03/24/2024 00:23:52 - INFO - trainer.trainer - Epoch 17 finished. Took 18.59 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch:  90%|█████████ | 18/20 [05:34<00:37, 18.56s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A
Iteration:  23%|██▎       | 9/39 [00:04<00:14,  2.14it/s][A
Iteration:  26%|██▌       | 10/39 [00:04<00:13,  2.14it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:13,  2.14it/s][A
Iteration:  31%|███       | 12/39 [00:05<00:12,  2.14it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.14it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:11,  2.14it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.13it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.13it/s][A
Iteration:  44%|████▎     | 17/39 [00:07<00:10,  2.13it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.13it/s][A
Iteration:  49%|████▊     | 19/39 [00:08<00:09,  2.14it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.14it/s][A
Iteration:  54%|█████▍    | 21/39 [00:09<00:08,  2.14it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.14it/s][A
Iteration:  59%|█████▉    | 23/39 [00:10<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:11<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:12<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:14<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:15<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:16<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:17<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:24:10 - INFO - trainer.trainer - Epoch 18 finished. Took 18.19 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.14it/s]
Epoch:  95%|█████████▌| 19/20 [05:52<00:18, 18.45s/it]
Iteration:   0%|          | 0/39 [00:00<?, ?it/s][A
Iteration:   3%|▎         | 1/39 [00:00<00:17,  2.14it/s][A
Iteration:   5%|▌         | 2/39 [00:00<00:17,  2.14it/s][A
Iteration:   8%|▊         | 3/39 [00:01<00:16,  2.14it/s][A
Iteration:  10%|█         | 4/39 [00:01<00:16,  2.14it/s][A
Iteration:  13%|█▎        | 5/39 [00:02<00:15,  2.14it/s][A
Iteration:  15%|█▌        | 6/39 [00:02<00:15,  2.14it/s][A
Iteration:  18%|█▊        | 7/39 [00:03<00:14,  2.14it/s][A
Iteration:  21%|██        | 8/39 [00:03<00:14,  2.14it/s][A[INFO|trainer.py:570] 2024-03-24 00:24:14,744 >> The following columns in the evaluation set  don't have a corresponding argument in `CoFiBertForSequenceClassification.forward` and have been ignored: idx, sentence2, sentence1. If idx, sentence2, sentence1 are not expected by `CoFiBertForSequenceClassification.forward`,  you can safely ignore this message.
03/24/2024 00:24:14 - INFO - trainer.trainer - ***** Running Evaluation *****
03/24/2024 00:24:14 - INFO - trainer.trainer -   Num examples = 277
03/24/2024 00:24:14 - INFO - trainer.trainer -   Batch size = 32


Evaluation:   0%|          | 0/9 [00:00<?, ?it/s][A[A

Evaluation:  33%|███▎      | 3/9 [00:00<00:00, 21.42it/s][A[A

Evaluation:  67%|██████▋   | 6/9 [00:00<00:00, 21.41it/s][A[A

Evaluation: 100%|██████████| 9/9 [00:00<00:00, 22.48it/s][A[AEvaluation: 100%|██████████| 9/9 [00:00<00:00, 22.18it/s]03/24/2024 00:24:15 - INFO - datasets.metric - Removing /scratch/network/hw8161/.cache/huggingface/metrics/glue/rte/default_experiment-1-0.arrow
03/24/2024 00:24:15 - INFO - trainer.trainer - Evaluating: {'accuracy': 0.6714801444043321, 'eval_loss': 0.869359, 'step': 750}


Iteration:  23%|██▎       | 9/39 [00:04<00:17,  1.67it/s][A
Iteration:  26%|██▌       | 10/39 [00:05<00:16,  1.79it/s][A
Iteration:  28%|██▊       | 11/39 [00:05<00:14,  1.89it/s][A
Iteration:  31%|███       | 12/39 [00:06<00:13,  1.96it/s][A
Iteration:  33%|███▎      | 13/39 [00:06<00:12,  2.01it/s][A
Iteration:  36%|███▌      | 14/39 [00:06<00:12,  2.05it/s][A
Iteration:  38%|███▊      | 15/39 [00:07<00:11,  2.07it/s][A
Iteration:  41%|████      | 16/39 [00:07<00:10,  2.09it/s][A
Iteration:  44%|████▎     | 17/39 [00:08<00:10,  2.11it/s][A
Iteration:  46%|████▌     | 18/39 [00:08<00:09,  2.12it/s][A
Iteration:  49%|████▊     | 19/39 [00:09<00:09,  2.12it/s][A
Iteration:  51%|█████▏    | 20/39 [00:09<00:08,  2.13it/s][A
Iteration:  54%|█████▍    | 21/39 [00:10<00:08,  2.13it/s][A
Iteration:  56%|█████▋    | 22/39 [00:10<00:07,  2.13it/s][A
Iteration:  59%|█████▉    | 23/39 [00:11<00:07,  2.14it/s][A
Iteration:  62%|██████▏   | 24/39 [00:11<00:07,  2.14it/s][A
Iteration:  64%|██████▍   | 25/39 [00:12<00:06,  2.14it/s][A
Iteration:  67%|██████▋   | 26/39 [00:12<00:06,  2.14it/s][A
Iteration:  69%|██████▉   | 27/39 [00:13<00:05,  2.14it/s][A
Iteration:  72%|███████▏  | 28/39 [00:13<00:05,  2.14it/s][A
Iteration:  74%|███████▍  | 29/39 [00:13<00:04,  2.14it/s][A
Iteration:  77%|███████▋  | 30/39 [00:14<00:04,  2.14it/s][A
Iteration:  79%|███████▉  | 31/39 [00:14<00:03,  2.14it/s][A
Iteration:  82%|████████▏ | 32/39 [00:15<00:03,  2.14it/s][A
Iteration:  85%|████████▍ | 33/39 [00:15<00:02,  2.14it/s][A
Iteration:  87%|████████▋ | 34/39 [00:16<00:02,  2.14it/s][A
Iteration:  90%|████████▉ | 35/39 [00:16<00:01,  2.14it/s][A
Iteration:  92%|█████████▏| 36/39 [00:17<00:01,  2.14it/s][A
Iteration:  95%|█████████▍| 37/39 [00:17<00:00,  2.14it/s][A
Iteration:  97%|█████████▋| 38/39 [00:18<00:00,  2.14it/s][A
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.21it/s][A03/24/2024 00:24:29 - INFO - trainer.trainer - Epoch 19 finished. Took 18.6 seconds.
Iteration: 100%|██████████| 39/39 [00:18<00:00,  2.10it/s]
Epoch: 100%|██████████| 20/20 [06:10<00:00, 18.49s/it]Epoch: 100%|██████████| 20/20 [06:10<00:00, 18.54s/it]
[INFO|configuration_utils.py:439] 2024-03-24 00:24:29,138 >> Configuration saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/config.json
[INFO|modeling_utils.py:1084] 2024-03-24 00:24:30,079 >> Model weights saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/pytorch_model.bin
[INFO|tokenization_utils_base.py:2094] 2024-03-24 00:24:30,080 >> tokenizer config file saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2100] 2024-03-24 00:24:30,081 >> Special tokens file saved in /scratch/network/hw8161/CoFiPruning/out/RTE/CoFi/RTE_sparsity0.6/FT-lr3e-5/special_tokens_map.json
03/24/2024 00:24:30 - INFO - __main__ - Training took 386.65 seconds.
